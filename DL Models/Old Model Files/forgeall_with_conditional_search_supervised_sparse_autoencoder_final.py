# -*- coding: utf-8 -*-
"""FORGEall - With Conditional Search - Supervised Sparse Autoencoder - FINAL.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1md46TjP80ciK0JGJAvKSfqt4qxEVENt2
"""

'''
1. This v8 code below is SUPERVISED version of the code for HEA model performance.
2. The data file used as input is: df_298_cleaned_filtered_1 (w_entropy).csv
3. The code also depends on a utility .py file called general_file_utilities.py for some file and stats related functionality
4. The supervised model has several hyper params:
        These two are passed in as part of model compile
            loss_weight_sparse
            loss_weight_divergence
        The others are part of model creation, sent in as a param grid dictionary. Param grid will run permutations to find best model and model params.
          param_grid = {
            'hidden_dim': [8, 10, 12],
            'latent_dim': [4, 6, 8],
            'target_sparsity': [0.05, 0.08 ],
            'batch_size': [8]
          }

'''

!pip install GPUtil

"""# << - - - SETUP Profiling - - ->>"""

from tensorflow.keras.callbacks import TensorBoard

# Define a log directory for storing logs
log_dir = "./logs"

# Create a TensorBoard callback with profiling enabled
tensorboard_callback = TensorBoard(
    log_dir=log_dir,
    histogram_freq=1,
    profile_batch='5,15'  # Profile batches 5 to 15
)

def print_current_timestamp_in_pst():
    """
    Prints the current timestamp in Pacific Standard Time (PST).
    """
    !pip install pytz

    from datetime import datetime
    import pytz

    # Get the current UTC time
    current_time_utc = datetime.now(pytz.utc)

    # Convert the current time to PST (Pacific Standard Time)
    pst_timezone = pytz.timezone('US/Pacific')
    current_time_pst = current_time_utc.astimezone(pst_timezone)

    # Print the current timestamp in PST with proper formatting
    print("Current Timestamp in PST:", current_time_pst.strftime("%Y-%m-%d %H:%M:%S %Z"))

# Call the function to print the timestamp
print_current_timestamp_in_pst()

"""# << - - - - Prepare the data"""

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split

# Set random seed for reproducibility
np.random.seed(10)

# Step 1: Load and clean the dataset
def load_and_clean_data(file_path, columns_to_drop, target_column, drop_columns_list):
    """
    Loads the dataset, drops irrelevant columns, calculates correlation matrix, and drops columns with high correlation.

    Args:
    - file_path (str): Path to the CSV file.
    - columns_to_drop (list): List of column names to drop initially.
    - target_column (str): Column to calculate correlation against.
    - drop_columns_list (list): Columns to drop based on analysis.

    Returns:
    - df (DataFrame): Cleaned dataframe.
    - X_train (DataFrame): Feature data without target column.
    - y_train (Series): Target column data.
    """
    # Load dataset
    df = pd.read_csv(file_path)

    # Drop irrelevant columns
    df = df.drop(columns=columns_to_drop, axis=1)

    # Display correlation matrix (optional step for analysis)
    corr_matrix = df.corr()
    print(corr_matrix[target_column].sort_values(ascending=False))

    # Drop columns based on analysis
    df = df.drop(columns=drop_columns_list, axis=1)

    # Split features and target
    X_train = df.drop(target_column, axis=1)
    y_train = df[target_column]


    process_conditions = ['Hom_Temp(K)', 'R(%)', 'CR(%)', 'Anneal_Temp(K)', 'Anneal_Time(h)']

    for condition in process_conditions:
      print(condition + ' unique values')
      print(X_train[condition].unique)

    print(y_train.max)
    return df, X_train, y_train

# Step 2: Convert atomic percentage to weight percentage
def convert_atomic_to_weight(X_train):
    """
    Molar mass is the mass of one mole of a given substance, which can be an
    element or a compound. It is typically expressed in grams per mole (g/mol).
    The molar mass of a substance is equivalent to the sum of the atomic masses of all atoms
    in a molecule of that substance, as represented in atomic mass units (amu), but
    converted to grams for use in macroscopic quantities.

    For elements:
    The molar mass of an element is numerically equal to its atomic mass
    (in atomic mass units), but in grams per mole. For example, the molar mass of carbon (C)
    is approximately 12.01 g/mol, because one mole of carbon atoms weighs about 12.01 grams.

    This function converts atomic percentages to weight percentages for relevant elements.
    currently, mol ratios written as a percentage of the whole. Dividing by 100 and multiplying
    by the molar mass gives the molar weight with respect to other elements

    Args:
    - X_train (DataFrame): Feature dataframe with atomic percentages.

    Returns:
    - X_train (DataFrame): Updated feature dataframe with weight percentages.
    """
    # Define atomic masses for each element
    atomic_masses = {
        'C(at%)': 12.01, 'Co(at%)': 58.93, 'Al(at%)': 26.98, 'V(at%)': 50.94,
        'Cr(at%)': 51.99, 'Mn(at%)': 54.94, 'Fe(at%)': 55.85, 'Ni(at%)': 58.69,
        'Cu(at%)': 63.55, 'Mo(at%)': 95.96
    }

    # Convert atomic percentages to weight percentages
    for element, mass in atomic_masses.items():
        X_train[element] = (X_train[element] / 100) * mass

    # Rename columns to indicate weight percentages
    X_train = X_train.rename(columns={f'{key}': key.replace('(at%)', '(wt)') for key in atomic_masses.keys()})

    X_train = X_train.rename(columns={
        'R(%)' : 'R',
        'CR(%)': 'CR'
    })
    # Normalize percentages for R and CR
    X_train['R'] = X_train['R'] / 100
    X_train['CR'] = X_train['CR'] / 100



    return X_train

# Step 3: Normalize features using MinMaxScaler
def normalize_features(X_train, y_train):
    """
    Normalizes the feature and target data using MinMaxScaler.

    Args:
    - X_train (DataFrame): Feature data.
    - y_train (Series): Target data (Yield Strength).

    Returns:
    - X_train_normalized (DataFrame): Normalized feature data.
    - y_train_normalized (DataFrame): Normalized target data.
    """
    scaler = MinMaxScaler()

    # Normalize features
    X_train_normalized = scaler.fit_transform(X_train)
    X_train_normalized = pd.DataFrame(X_train_normalized, columns=X_train.columns)

    # Normalize target
    y_train_normalized = scaler.fit_transform(y_train.values.reshape(-1, 1))
    y_train_normalized = pd.DataFrame(y_train_normalized, columns=['YS(Mpa)'])

    return X_train_normalized, y_train_normalized

# Step 4: Check for missing values (NaN) in the dataset
def check_missing_values(X_train):
    """
    Checks for missing values (NaN) in the dataset and prints out the columns with NaNs.

    Args:
    - X_train (DataFrame): Feature data.

    Returns:
    - None
    """
    nan_counts = X_train.isna().sum()
    columns_with_nan = X_train.columns[X_train.isna().any()].tolist()

    print("NaN counts per column:")
    print(nan_counts)
    print("\nColumns with NaN values:")
    print(columns_with_nan)

# Step 5: Split the data into training and testing sets
def split_data(X_train_normalized, y_train_normalized, test_size=0.2, random_state=42):
    """
    Splits the data into training and testing sets.

    Args:
    - X_train_normalized (DataFrame): Normalized feature data.
    - y_train_normalized (DataFrame): Normalized target data.
    - test_size (float): Proportion of data to include in the test set.
    - random_state (int): Random seed for reproducibility.

    Returns:
    - train_data (DataFrame): Training feature data.
    - test_data (DataFrame): Testing feature data.
    - train_labels (DataFrame): Training target data.
    - test_labels (DataFrame): Testing target data.
    """
    return train_test_split(X_train_normalized, y_train_normalized, test_size=test_size, random_state=random_state)

# Main function to execute the pipeline
def prep_hea_data():
    # File path to the dataset
    file_path = 'df_298_cleaned_longer(w_entropy) - df_298_cleaned.csv'

    # Columns to drop during cleaning
    columns_to_drop = ['Enthalpy_BCC', 'Enthalpy_HCP', 'G_RT_BCC', 'G_RT_HCP',
                       'dG_RT_(BCC - FCC)', 'dG_RT_(HCP - FCC)', 'dG_RT_(BCC - HCP)',
                       'dG_AT_(BCC - FCC)', 'dG_AT_(HCP - FCC)', 'dG_AT_(BCC - HCP)',
                       'H_RT_BCC', 'H_RT_HCP']

    # Target column for prediction
    target_column = 'YS(Mpa)'

    # Additional columns to drop based on correlation analysis
    drop_columns_list = ['phase_fraction_hcp']

    # Load and clean the data
    df, X_train, y_train = load_and_clean_data(file_path, columns_to_drop, target_column, drop_columns_list)

    # Convert atomic percentages to weight percentages
    X_train = convert_atomic_to_weight(X_train)

    # Normalize features and target
    X_train_normalized, y_train_normalized = normalize_features(X_train, y_train)

    # Check for missing values
    check_missing_values(X_train)

    # Split data into training and testing sets
    train_data, test_data, train_labels, test_labels = split_data(X_train_normalized, y_train_normalized)

    # Print shapes of train and test sets
    print("Training data shape:", train_data.shape)
    print("Test data shape:", test_data.shape)
    return train_data, test_data, train_labels, test_labels

train_data, test_data, train_labels, test_labels= prep_hea_data()
print_current_timestamp_in_pst()
print(train_data.columns)

print(train_data.head())

"""### <---Conditional Random Data--->




"""

import pandas as pd
df = pd.read_csv('df_298_cleaned_longer(w_entropy) - df_298_cleaned.csv')

# Main function to execute the pipeline
def prep_hea_data_conditional():
    # File path to the dataset
    file_path = 'df_298_cleaned_longer(w_entropy) - df_298_cleaned.csv'

    # Columns to drop during cleaning
    columns_to_drop = ['Enthalpy_BCC', 'Enthalpy_HCP', 'G_RT_BCC', 'G_RT_HCP',
                       'dG_RT_(BCC - FCC)', 'dG_RT_(HCP - FCC)', 'dG_RT_(BCC - HCP)',
                       'dG_AT_(BCC - FCC)', 'dG_AT_(HCP - FCC)', 'dG_AT_(BCC - HCP)',
                       'H_RT_BCC', 'H_RT_HCP']

    # Target column for prediction
    target_column = 'YS(Mpa)'

    # Additional columns to drop based on correlation analysis
    drop_columns_list = ['phase_fraction_hcp']

    # Load and clean the data
    df, X_train_new, y_train_new = load_and_clean_data(file_path, columns_to_drop, target_column, drop_columns_list)

    # Convert atomic percentages to weight percentages



    return X_train_new, y_train_new

X_train_new, y_train_new= prep_hea_data_conditional()
print_current_timestamp_in_pst()
print(X_train_new.head())

elemental_features = ['C(at%)', 'Al(at%)', 'V(at%)', 'Cr(at%)', 'Mn(at%)', 'Fe(at%)', 'Co(at%)', 'Ni(at%)', 'Cu(at%)', 'Mo(at%)']
for element in elemental_features:
  print("max", element, X_train_new[element].max())
  print("min", element, X_train_new[element].min())

import pandas as pd
import numpy as np
from itertools import product
import random

# Elemental features
elemental_features = ['C(at%)', 'Al(at%)', 'V(at%)', 'Cr(at%)', 'Mn(at%)', 'Fe(at%)', 'Co(at%)', 'Ni(at%)', 'Cu(at%)', 'Mo(at%)']

# Processing conditions
processing_conditions = ['Anneal_Temp(K)', 'Anneal_Time(h)', 'R(%)', 'CR(%)', 'Hom_Temp(K)']

processing_condition_values = {
    'Anneal_Temp(K)': X_train_new['Anneal_Temp(K)'].unique(),
    'Anneal_Time(h)': X_train_new['Anneal_Time(h)'].unique(),
    'R(%)': X_train_new['R(%)'].unique(),
    'CR(%)': X_train_new['CR(%)'].unique(),
    'Hom_Temp(K)': X_train_new['Hom_Temp(K)'].unique()
}



# Define min, max, and increment for each element
elemental_limits = {
    'C(at%)': (0.0, 0.1),   # Min: 0.0, Max: 0.1
    'Al(at%)': (0.0, 0.5),  # Min: 0.0, Max: 0.5
    'V(at%)': (0.0, 0.1),   # Min: 0.0, Max: 0.1
    'Cr(at%)': (0.0, 0.4),  # Min: 0.0, Max: 0.4
    'Mn(at%)': (0.0, 0.1),  # Min: 0.0, Max: 0.1
    'Fe(at%)': (0.0, 0.3),  # Min: 0.2, Max: 0.3
    'Co(at%)': (0.0, 0.2), # Min: 0.0, Max: 0.2
    'Ni(at%)': (0.0, 0.2),  # Min: 0.0, Max: 0.2
    'Cu(at%)': (0.0, 0.1),  # Min: 0.0, Max: 0.1
    'Mo(at%)': (0.0, 0.1),  # Min: 0.0, Max: 0.1
}
increment = 0.1
# Generate systematic combinations for elemental compositions
def generate_compositions(elemental_limits, increment):
    # Create a range of values for each element
    ranges = {
        element: np.arange(elemental_limits[element][0], elemental_limits[element][1] + increment, increment)
        for element in elemental_limits
    }
    for element, values in ranges.items():
      print(f"{element}: {values}")

    # Generate all combinations
    combinations = list(product(*ranges.values()))
    print(combinations)

    # Convert combinations to a DataFrame
    compositions = pd.DataFrame(combinations, columns=ranges.keys())

    # Normalize compositions to sum to 100%
    compositions['Sum'] = compositions.sum(axis=1)
    for feature in ranges.keys():
        compositions[feature] = compositions[feature] / compositions['Sum'] * 100
    compositions = compositions.drop(columns=['Sum'])


    return compositions


# Generate thermodynamic properties
def calculate_thermodynamic_properties(X):
    def calculate_config_entropy(row):
        entropy = -8.314 * sum(
            (row[feature]/100) * (0 if row[feature] == 0 else np.log(row[feature]/100))
            for feature in elemental_features
        )
        return entropy

    X['Config_Entropy'] = X.apply(calculate_config_entropy, axis=1)
    X['(0-T)*Entropy'] = 298 * (0 - X['Config_Entropy'])
    return X

# Generate random processing conditions
def generate_processing_conditions(num_samples, processing_condition_values):
    """
    Generates random processing conditions based on predefined static ranges.

    Args:
        num_samples (int): Number of samples to generate.
        processing_condition_values (dict): Static ranges for each processing condition.

    Returns:
        DataFrame: A DataFrame containing randomly sampled processing conditions.
    """
    processing_conditions_df = pd.DataFrame()
    for condition, values in processing_condition_values.items():
        processing_conditions_df[condition] = random.choices(values, k=num_samples)
    return processing_conditions_df


# Generate a completely new dataset
def generate_new_dataset():
    # Systematic elemental compositions
    systematic_compositions = generate_compositions(elemental_limits, increment)

    # Thermodynamic properties
    dataset_with_properties = calculate_thermodynamic_properties(systematic_compositions)

    # Processing conditions
    num_samples = len(dataset_with_properties)
    new_processing_conditions = generate_processing_conditions(num_samples, processing_condition_values)

    # Combine all features
    new_dataset = pd.concat([dataset_with_properties, new_processing_conditions], axis=1)
    return new_dataset

# Generate and print the dataset
new_dataset = generate_new_dataset()
new_dataset = new_dataset.round(4)

# Assuming your dataset is in a DataFrame named 'new_dataset'
filtered_dataset = new_dataset[
    (new_dataset['Config_Entropy'] >= 12) &
    (new_dataset['Al(at%)'] != 0) &
    (new_dataset['Co(at%)'] != 0) &
    (new_dataset['Cr(at%)'] != 0) &
    (new_dataset['Fe(at%)'] != 0) &
    (new_dataset['Ni(at%)'] != 0)
]
# Print the filtered dataset
print(filtered_dataset)

"""columns now needed:

 - grain size
 - melting point
 - Gibbs_FCC
 - Enthalpy_FCC
 - phase fraction fcc
 - second phase fraction

Prepare generated data for testing
"""

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
new_dataset = pd.read_csv('new_dataset.csv')
#Step 2: Convert atomic percentage to weight percentage
def convert_atomic_to_weight(df):
    """
    Molar mass is the mass of one mole of a given substance, which can be an
    element or a compound. It is typically expressed in grams per mole (g/mol).
    The molar mass of a substance is equivalent to the sum of the atomic masses of all atoms
    in a molecule of that substance, as represented in atomic mass units (amu), but
    converted to grams for use in macroscopic quantities.

    For elements:
    The molar mass of an element is numerically equal to its atomic mass
    (in atomic mass units), but in grams per mole. For example, the molar mass of carbon (C)
    is approximately 12.01 g/mol, because one mole of carbon atoms weighs about 12.01 grams.

    This function converts atomic percentages to weight percentages for relevant elements.
    currently, mol ratios written as a percentage of the whole. Dividing by 100 and multiplying
    by the molar mass gives the molar weight with respect to other elements

    Args:
    - X_train (DataFrame): Feature dataframe with atomic percentages.

    Returns:
    - X_train (DataFrame): Updated feature dataframe with weight percentages.
    """
    # Define atomic masses for each element
    atomic_masses = {
        'C(at%)': 12.01, 'Co(at%)': 58.93, 'Al(at%)': 26.98, 'V(at%)': 50.94,
        'Cr(at%)': 51.99, 'Mn(at%)': 54.94, 'Fe(at%)': 55.85, 'Ni(at%)': 58.69,
        'Cu(at%)': 63.55, 'Mo(at%)': 95.96
    }

    # Convert atomic percentages to weight percentages
    for element, mass in atomic_masses.items():
        df[element] = (df[element] / 100) * mass

    # Rename columns to indicate weight percentages
    df = df.rename(columns={f'{key}': key.replace('(at%)', '(wt)') for key in atomic_masses.keys()})

    df = df.rename(columns={
        'R(%)' : 'R',
        'CR(%)': 'CR'
    })
    # Normalize percentages for R and CR
    df['R'] = df['R'] / 100
    df['CR'] = df['CR'] / 100



    return df

# Step 3: Normalize features using MinMaxScaler
def normalize_features(df):
    """
    Normalizes the feature and target data using MinMaxScaler.

    Args:
    - X_train (DataFrame): Feature data.
    - y_train (Series): Target data (Yield Strength).

    Returns:
    - X_train_normalized (DataFrame): Normalized feature data.
    - y_train_normalized (DataFrame): Normalized target data.
    """
    scaler = MinMaxScaler()

    # Normalize features
    df_normalized= scaler.fit_transform(df)
    df_normalized = pd.DataFrame(df_normalized, columns=df.columns)

    return df_normalized

new_dataset_adjusted = convert_atomic_to_weight(new_dataset)
new_dataset_normalized = normalize_features(new_dataset_adjusted)

"""columns now needed:
 - grain size
 - melting point
 - Gibbs_FCC
 - Enthalpy_FCC
- phase fraction fcc
- second phase fraction

# <<< Setup the SupervisedSparseAutoencoder class  >>>
"""

import tensorflow as tf
from tensorflow import keras

class SupervisedSparseAutoencoder:
    def __init__(self, hidden_dim, latent_dim, input_dim, target_sparsity=0.05):
        self.latent_dim = latent_dim
        self.hidden_dim = hidden_dim
        self.input_dim = input_dim
        self.target_sparsity = target_sparsity
        self._build_model()

    def _build_model(self):
        # Input layer
        input_data = keras.layers.Input(shape=(self.input_dim,))

        # Encoder
        encoded = keras.layers.Dense(self.hidden_dim, activation='selu')(input_data)
        latent = keras.layers.Dense(self.latent_dim, activation='sigmoid')(encoded)

        # Decoder
        decoded = keras.layers.Dense(self.hidden_dim, activation='selu')(latent)
        output_data = keras.layers.Dense(self.input_dim, activation='sigmoid')(decoded)

        # Prediction Layer (Supervised Component)
        prediction = keras.layers.Dense(1, activation='relu')(latent)

        # Autoencoder Model with Two Outputs
        self.autoencoder = keras.Model(inputs=input_data, outputs=[output_data, prediction])
        self.encoder = keras.Model(inputs=input_data, outputs=latent)

    def kl_divergence_loss(self, target_sparsity, actual_sparsity):
        return target_sparsity * tf.math.log(target_sparsity / (actual_sparsity + 1e-10)) + \
               (1 - target_sparsity) * tf.math.log((1 - target_sparsity) / (1 - actual_sparsity + 1e-10))

    def sparse_loss(self, y_true, y_pred):
        # Reconstruction loss (Mean Squared Error)
        reconstruction_loss = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)

        # Calculate the average activation of the latent layer
        latent_output = self.encoder(y_true)
        actual_sparsity = tf.reduce_mean(latent_output, axis=0)

        # KL Loss
        kl_loss = tf.reduce_sum(self.kl_divergence_loss(self.target_sparsity, actual_sparsity))
        return reconstruction_loss + kl_loss

    def compile(self, optimizer='adam', loss_weights=None):
        self.autoencoder.compile(optimizer=optimizer,
                                 loss=[self.sparse_loss, 'mean_squared_error'],
                                 loss_weights=loss_weights)  # Adjust loss weights as needed

    def fit(self, train_data, train_labels, epochs=10, batch_size=256, validation_data=None, callbacks=None):
        return self.autoencoder.fit(train_data,
                                    [train_data, train_labels],
                                    epochs=epochs,
                                    batch_size=batch_size,
                                    shuffle=False,
                                    validation_data=validation_data,
                                    callbacks=callbacks)

    def evaluate_sparsity(self, x_data):
        latent_representations = self.encoder.predict(x_data)
        sparsity = np.mean(np.abs(latent_representations) < 1e-3)
        return sparsity * 100

    def predict_latent(self, x_data):
        return self.encoder.predict(x_data)

    def decoded_output(self, x_data):
        return self.autoencoder.predict(x_data)

    def fine_tune_regression(self, train_data, train_labels, epochs=5, learning_rate=1e-4):
        """
        Option to fine-tune the latent space for the regression task.
        - Freeze encoder weights and only update the regression output layer.
        """
        for layer in self.encoder.layers:
            layer.trainable = False  # Freeze encoder layers

        # Compile again with a smaller learning rate and only train the regression output
        self.autoencoder.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate),
                                 loss=[self.sparse_loss, 'mean_squared_error'],
                                 loss_weights=[0.4, 1.0])  # Equal weight for both losses

        # Fit only on regression
        self.autoencoder.fit(train_data,
                             [train_data, train_labels],  # Same inputs but focus is on regression
                             epochs=epochs,
                             shuffle=True)

"""# << - - -Now start the training - - - >

<<- - - Utility fn to commit training stats to file - - >>
"""

def append_training_stats_to_csv(best_result, filename='hea_model_training_results.csv'):

    from datetime import datetime
    import pytz
    import os
    import csv

    # Get the current time in PST
    pst = pytz.timezone('US/Pacific')
    current_time_pst = datetime.now(pst).strftime('%Y-%m-%d %H:%M:%S')

    # Prepare the row with the timestamp as the first field
    row = {'timestamp_PST': current_time_pst}

    # Add all key-value pairs from best_result to the row
    row.update(best_result)

    # Check if the file exists
    file_exists = os.path.isfile(filename)

    # If the file exists, read the current fieldnames (headers)
    if file_exists:
        with open(filename, mode='r') as file:
            reader = csv.DictReader(file)
            existing_fieldnames = reader.fieldnames
    else:
        existing_fieldnames = []

    # Combine the existing fieldnames with any new ones from the current row
    # Ensuring 'timestamp_PST' is always the first column
    fieldnames = ['timestamp_PST'] + [fn for fn in row.keys() if fn != 'timestamp_PST']

    # ** Inspect the fieldnames **
    #print("Fieldnames being used:")
    #print(fieldnames)

    # Open the file in append mode ('a') and create a CSV DictWriter
    with open(filename, mode='a', newline='') as file:
        writer = csv.DictWriter(file, fieldnames=fieldnames)

        # If the file doesn't exist, write the header first
        if not file_exists:
            writer.writeheader()

        # Append the row of data
        writer.writerow(row)

"""<<- - - Actual training - - >>"""

train_data.shape

from itertools import product
from datetime import datetime

print_current_timestamp_in_pst()

# Reshape labels for Keras (they need to be 2D arrays)
# Reshape labels for Keras (they need to be 2D arrays)
train_labels_autoencoder = train_labels.values.reshape(-1, 1) # Use .values to get the NumPy array from the DataFrame
test_labels_autoencoder = test_labels.values.reshape(-1, 1) # Use .values to get the NumPy array from the DataFrame

# Define the strategy
strategy = tf.distribute.MirroredStrategy()

# Define the parameter grid
param_grid = {
    'hidden_dim': [16, 18],
    'latent_dim': [6],
    'target_sparsity': [0.09],
    'batch_size': [4]
}

# Generate all combinations
param_combinations = list(product(param_grid['hidden_dim'],
                                  param_grid['latent_dim'],
                                  param_grid['target_sparsity'],
                                  param_grid['batch_size']))

# List to store results
results               = []
loss_weight_divergence= 0.6       #< - - - - - - - - - - - - - - - - - Set the Divergence loss weight here..
loss_weight_sparse    = 0.4       #< - - - - - - - - - - - - - - - - - Set the SPARSE loss weight here..


# Loop over all combinations
for hidden_dim, latent_dim, target_sparsity, batch_size in param_combinations:
    print(f'Training with hidden_dim={hidden_dim}, latent_dim={latent_dim}, '
          f'target_sparsity={target_sparsity}, batch_size={batch_size}')
    # Clear previous session
    tf.keras.backend.clear_session()

    with strategy.scope():
        # Build the model
        sparse_autoencoder = SupervisedSparseAutoencoder(input_dim=25,  # Adjust input_dim as needed
                                                         hidden_dim=hidden_dim,
                                                         latent_dim=latent_dim,
                                                         target_sparsity=target_sparsity)
        sparse_autoencoder.compile(optimizer='adam', loss_weights=[loss_weight_sparse, loss_weight_divergence])

        # Fit the model
        history = sparse_autoencoder.fit(train_data,
                                         train_labels_autoencoder,
                                         epochs=32,
                                         batch_size=batch_size,
                                         validation_data=(test_data, [test_data, test_labels_autoencoder]),
                                         callbacks=[tensorboard_callback])  # Include your callbacks if any

    # Get validation loss from history
    val_loss = history.history['val_loss'][-1]
    #val_reconstruction_loss = history.history['val_reconstruction_output_loss'][-1]
    #val_prediction_loss = history.history['val_prediction_output_loss'][-1]

    # Record the results
    results.append({
        'hidden_dim': hidden_dim,
        'latent_dim': latent_dim,
        'target_sparsity': target_sparsity,
        'batch_size': batch_size,
        'val_loss': val_loss
        #'val_reconstruction_loss': val_reconstruction_loss,
        #'val_prediction_loss': val_prediction_loss
    })

# Convert results to DataFrame
results_df = pd.DataFrame(results)

# Find the best combination
best_result = results_df.loc[results_df['val_loss'].idxmin()]

print("Best parameters:")
print(f"hidden_dim: {best_result['hidden_dim']}")
print(f"latent_dim: {best_result['latent_dim']}")
print(f"target_sparsity: {best_result['target_sparsity']}")
print(f"batch_size: {best_result['batch_size']}")
print(f"Validation loss: {best_result['val_loss']}")

best_result_copy = best_result.copy()

# Assuming best_result is a slice of a DataFrame and you want to add new values
best_result_copy['loss_weight_sparse'] = loss_weight_sparse
best_result_copy['loss_weight_divergence'] = loss_weight_divergence

print_current_timestamp_in_pst()

"""# - - - - - - - << Now instantiate an object of the model for the best hyper param's found from the grid searched model training, and fit the data"""

# Use the strategy scope
print_current_timestamp_in_pst()

with strategy.scope():
  sparse_autoencoder_to_disk = SupervisedSparseAutoencoder(input_dim=24, hidden_dim=int(best_result['hidden_dim']), latent_dim=int(best_result['latent_dim']), target_sparsity=best_result['target_sparsity'])
  sparse_autoencoder_to_disk.compile(optimizer='adam')

print_current_timestamp_in_pst()

with strategy.scope():
  history = sparse_autoencoder_to_disk.fit(train_data,
                                  train_labels_autoencoder,
                                  epochs=32,
                                  batch_size=4,
                                  validation_data=(test_data, [test_data, test_labels_autoencoder]),
                                  callbacks=[tensorboard_callback]
                                  )
  #sparse_autoencoder_to_disk.fine_tune_regression(train_data, train_labels, epochs=10, learning_rate=1e-4)

# Saving the entire autoencoder model and the encoder
#sparse_autoencoder_to_disk.autoencoder.save('./hea_sparse_autoencoder_full_model.h5')  # Save the full autoencoder model
#sparse_autoencoder_to_disk.encoder.save('./hea_sparse_autoencoder_encoder_model.h5')  # Save the encoder model separately

print_current_timestamp_in_pst()

"""# #- - - Load the model from the disk file.
# <<< Work In Progress >>>
"""

# Load the full autoencoder model
#sparse_autoencoder = keras.models.load_model('hea_sparse_autoencoder_full_model.h5', custom_objects={'sparse_loss': sparse_autoencoder.sparse_loss})
#sparse_autoencoder = sparse_autoencoder_to_disk
#Now get the latent values for this model
latent_train = sparse_autoencoder_to_disk.predict_latent(train_data)
latent_test = sparse_autoencoder_to_disk.predict_latent(test_data)




print_current_timestamp_in_pst()

latent_test_new = sparse_autoencoder_to_disk.predict_latent(new_dataset_normalized)

train_data.shape

"""# <<<< Run the regressors to compute the MSE's and R2's >>>>

# -- - - <<<< KNN regressor with Grid search & feature importances >>> - -
"""

# Import libraries
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import RobustScaler
from sklearn.preprocessing import MinMaxScaler
from sklearn.inspection import permutation_importance
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime

# Extract latent representations
latent_train  = sparse_autoencoder_to_disk.encoder.predict(train_data)
latent_test   = sparse_autoencoder_to_disk.encoder.predict(test_data)

# Scale the latent features
#scaler = StandardScaler()
scaler = RobustScaler()
latent_train_scaled = scaler.fit_transform(latent_train)
latent_test_scaled = scaler.transform(latent_test)
latent_test_new_scaled = scaler.transform(latent_test_new)

# Define parameter grid
param_grid = {
    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],
    'n_neighbors': range(1, 51, 2),  # Test odd values from 1 to 49
    'weights': ['uniform', 'distance'],
    'metric': ['euclidean', 'manhattan', 'minkowski'],
    'p': [1, 2, 3]  # For Minkowski metric with different powers
}


# Grid search on latent data
grid_search_knn = GridSearchCV(
    estimator=KNeighborsRegressor(),
    param_grid=param_grid,
    cv=5,
    scoring='r2',
    n_jobs=-1
)
grid_search_knn.fit(latent_train_scaled, train_labels)
best_knn = grid_search_knn.best_estimator_
print("Best KNN Hyperparameters:", grid_search_knn.best_params_)

# Evaluate best model on latent data

# Import libraries
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import RobustScaler
from sklearn.preprocessing import MinMaxScaler
from sklearn.inspection import permutation_importance
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime

# Extract latent representations
latent_train  = sparse_autoencoder_to_disk.encoder.predict(train_data)
latent_test   = sparse_autoencoder_to_disk.encoder.predict(test_data)

# Scale the latent features
#scaler = StandardScaler()
scaler = RobustScaler()
latent_train_scaled = scaler.fit_transform(latent_train)
latent_test_scaled = scaler.transform(latent_test)

# Define parameter grid
param_grid = {
    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],
    'n_neighbors': range(1, 51, 2),  # Test odd values from 1 to 49
    'weights': ['uniform', 'distance'],
    'metric': ['euclidean', 'manhattan', 'minkowski'],
    'p': [1, 2, 3]  # For Minkowski metric with different powers
}


# Grid search on latent data
grid_search_knn = GridSearchCV(
    estimator=KNeighborsRegressor(),
    param_grid=param_grid,
    cv=5,
    scoring='r2',
    n_jobs=-1
)
grid_search_knn.fit(latent_train_scaled, train_labels)
best_knn = grid_search_knn.best_estimator_
print("Best KNN Hyperparameters:", grid_search_knn.best_params_)

# Evaluate best model on latent data

knn_predictions_test = best_knn.predict(latent_test_scaled)
knn_predictions_test_new  = best_knn.predict(latent_test_new_scaled)

print("\nBest KNN Regression Performance on Latent Test Data:")
print("MSE:", mean_squared_error(test_labels, knn_predictions_test))
print("RMSE:", np.sqrt(mean_squared_error(test_labels, knn_predictions_test)))
print("MAE:", np.mean(np.abs(test_labels - knn_predictions_test)))
print("R²:", r2_score(test_labels, knn_predictions_test))


'''
print("\nBest KNN Regression Performance on Random Conditional Test Data:")
print("MSE:", mean_squared_error(test_labels, knn_predictions_test_new))
print("RMSE:", np.sqrt(mean_squared_error(test_labels, knn_predictions_test_new)))
print("MAE:", np.mean(np.abs(test_labels - knn_predictions_test_new)))
print("R²:", r2_score(test_labels, knn_predictions_test_new))

'''

# - - - - - - -  - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
'''
# Step 2: Compute Permutation Importances
result = permutation_importance(
    estimator=best_knn,
    X=latent_test_scaled,
    y=test_labels,
    n_repeats=60,
    random_state=42,
    scoring='r2'
)
importances = result.importances_mean
std = result.importances_std

# Step 3: Interpret and Visualize
num_latent_features = latent_train_scaled.shape[1]
latent_feature_names = [f'Latent Feature {i+1}' for i in range(num_latent_features)]

# Create DataFrame
feature_importances = pd.DataFrame({
    'Feature': latent_feature_names,
    'Importance': importances,
    'Std': std
})
feature_importances.sort_values(by='Importance', ascending=False, inplace=True)

# Print feature importances
print("Permutation Feature Importances:")
print(feature_importances)

# Plot importances
plt.figure(figsize=(10, 6))
plt.barh(feature_importances['Feature'], feature_importances['Importance'], xerr=feature_importances['Std'])
plt.xlabel('Permutation Importance (Decrease in R²)')
plt.title('Feature Importances for KNN Regressor')
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()


Now map Latent Features Back to Original Features
To understand how original features contribute to important latent features:

Inspect Encoder Weights: Analyze the weights of the encoder to see how original features map to latent features.
Correlation Analysis: Compute the correlation between original features and important latent features.

# Get encoder weights
encoder_weights = sparse_autoencoder_to_disk.encoder.get_weights
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import RobustScaler
from sklearn.preprocessing import MinMaxScaler
from sklearn.inspection import permutation_importance
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime

# Extract latent representations
latent_train  = sparse_autoencoder_to_disk.encoder.predict(train_data)
latent_test   = sparse_autoencoder_to_disk.encoder.predict(test_data)

# Scale the latent features
#scaler = StandardScaler()
scaler = RobustScaler()
latent_train_scaled = scaler.fit_transform(latent_train)
latent_test_scaled = scaler.transform(latent_test)

# Define parameter grid
param_grid = {
    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],
    'n_neighbors': range(1, 51, 2),  # Test odd values from 1 to 49
    'weights': ['uniform', 'distance'],
    'metric': ['euclidean', 'manhattan', 'minkowski'],
    'p': [1, 2, 3]  # For Minkowski metric with different powers
}


# Grid search on latent data
grid_search_knn = GridSearchCV(
    estimator=KNeighborsRegressor(),
    param_grid=param_grid,
    cv=5,
    scoring='r2',
    n_jobs=-1
)
grid_search_knn.fit(latent_train_scaled, train_labels)
best_knn = grid_search_knn.best_estimator_
print("Best KNN Hyperparameters:", grid_search_knn.best_params_)

# Evaluate best model on latent data

knn_predictions_test = best_knn.predict(latent_test_scaled)

print("\nBest KNN Regression Performance on Latent Test Data:")
print("MSE:", mean_squared_error(test_labels, knn_predictions_test))
print("RMSE:", np.sqrt(mean_squared_error(test_labels, knn_predictions_test)))
print("MAE:", np.mean(np.abs(test_labels - knn_predictions_test)))
print("R²:", r2_score(test_labels, knn_predictions_test))
'''


# - - - - - - -  - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

'''
Now map Latent Features Back to Original Features
To understand how original features contribute to important latent features:

Inspect Encoder Weights: Analyze the weights of the encoder to see how original features map to latent features.
Correlation Analysis: Compute the correlation between original features and important latent features.

# Get encoder weights
encoder_weights = sparse_autoencoder_to_disk.encoder.get_weights

# - - - - - - -  - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

# Scale original data
scaler_orig = scaler
train_data_scaled = scaler_orig.fit_transform(train_data)
test_data_scaled = scaler_orig.transform(test_data)

# Grid search on original data
grid_search_knn_orig = GridSearchCV(
    estimator=KNeighborsRegressor(),
    param_grid=param_grid,
    cv=5,
    scoring='r2',
    n_jobs=-1
)
grid_search_knn_orig.fit(train_data_scaled, train_labels)
best_knn_orig = grid_search_knn_orig.best_estimator_
print("\nBest KNN Hyperparameters on Original Data:", grid_search_knn_orig.best_params_)

# Evaluate best model on original data
knn_orig_predictions_test = best_knn_orig.predict(test_data_scaled)

print("\nBest KNN Regression Performance on Original Test Data:")
print("MSE:", mean_squared_error(test_labels, knn_orig_predictions_test))
print("RMSE:", np.sqrt(mean_squared_error(test_labels, knn_orig_predictions_test)))
print("MAE:", np.mean(np.abs(test_labels - knn_orig_predictions_test)))
print("R²:", r2_score(test_labels, knn_orig_predictions_test))

# Step 2: Compute Permutation Importances for Original Data
result_orig = permutation_importance(
    estimator=best_knn_orig,
    X=test_data_scaled,
    y=test_labels,
    n_repeats=60,
    random_state=42,
    scoring='r2'
)

importances_orig = result_orig.importances_mean
std_orig = result_orig.importances_std

# Step 3: Interpret and Visualize for Original Data
num_orig_features = train_data_scaled.shape[1]
orig_feature_names = train_data.columns  # Assuming your original features have names from the dataframe

# Create DataFrame for original feature importances
feature_importances_orig = pd.DataFrame({
    'Feature': orig_feature_names,
    'Importance': importances_orig,
    'Std': std_orig
})
feature_importances_orig.sort_values(by='Importance', ascending=False, inplace=True)

# Print feature importances for original data
print("Permutation Feature Importances for Original Data:")
print(feature_importances_orig)


# Plot importances for original data
plt.figure(figsize=(10, 6))
plt.barh(feature_importances_orig['Feature'], feature_importances_orig['Importance'], xerr=feature_importances_orig['Std'])
plt.xlabel('Permutation Importance (Decrease in R²)')
plt.title('Feature Importances for KNN Regressor (Original Data)')
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()
'''

print_current_timestamp_in_pst()

# Filter predictions for high yield strength (e.g., above a certain threshold)
df=pd.read_csv('new_dataset.csv')

# Assuming knn_predictions_test_new contains the predicted yield strengths
# Sort the predictions in descending order and get the indices of the top 2
top_2_indices = np.argsort(knn_predictions_test_new)[-2:][::-1]

print(knn_predictions_test_new)

# Retrieve the corresponding rows from the dataset
top_2_heas = df.iloc[top_2_indices]

top_2_heas.to_csv('top_2_heas.csv', index=False)
# Print the top 2 HEAs
print(top_2_heas)

'''perform cross-validation to avoid overfitting'''
from sklearn.metrics import make_scorer, mean_squared_error, r2_score
import numpy as np

# Define a function to calculate RMSE and MAE as scorers
def rmse(y_true, y_pred):
    return np.sqrt(mean_squared_error(y_true, y_pred))

def mae(y_true, y_pred):
    return np.mean(np.abs(y_true - y_pred))

# Define scoring metrics for cross-validation
scoring = {
    'MSE': make_scorer(mean_squared_error),
    'RMSE': make_scorer(rmse),
    'MAE': make_scorer(mae),
    'R2': make_scorer(r2_score)
}

# Perform cross-validation on the test set using the best model
from sklearn.model_selection import cross_validate
'''
#first with original data
cv_results = cross_validate(
    best_knn_orig,
    train_data_scaled,
    train_labels,
    cv=10,
    scoring=scoring,
    n_jobs=-1
)

# Display cross-validation performance metrics
print("\nCross-Validation Performance on Original Test Data:")
for metric, scores in cv_results.items():
    if 'test' in metric:  # Filter only test scores
        metric_name = metric.split('_')[-1]
        print(f"{metric_name}: Mean={scores.mean():.4f}, Std={scores.std():.4f}")
'''
#second on latent space data

cv_results = cross_validate(
    best_knn,
    latent_train_scaled,
    train_labels,
    cv=10,
    scoring=scoring,
    n_jobs=-1
)

# Display cross-validation performance metrics
print("\nCross-Validation Performance on Latent Test Data:")
for metric, scores in cv_results.items():
    if 'test' in metric:  # Filter only test scores
        metric_name = metric.split('_')[-1]
        print(f"{metric_name}: Mean={scores.mean():.4f}, Std={scores.std():.4f}")



import numpy as np
import pandas as pd
from sklearn.model_selection import RandomizedSearchCV
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error, r2_score
from scipy.stats import randint, uniform

# Load the dataset
df = pd.read_csv('df_298_cleaned_longer(w_entropy).csv')

# Separate features and target variable
train_data = train_data

# Identify elemental features (e.g., C(at%), Al(at%), V(at%), etc.)
elemental_features = ['C(at%)', 'Al(at%)', 'V(at%)', 'Cr(at%)', 'Mn(at%)', 'Fe(at%)', 'Co(at%)', 'Ni(at%)', 'Cu(at%)', 'Mo(at%)']

# Normalize the elemental features to ensure they sum to 100%
def normalize_elemental_features(train_data):
    X_normalized = train_data.copy()
    elemental_sum = train_data[elemental_features].sum(axis=1)
    for feature in elemental_features:
        X_normalized[feature] = train_data[feature] / elemental_sum * 100
    return X_normalized

# Define custom parameter distributions for each elemental feature
elemental_distributions = {
    feature: uniform(loc=train_data[feature].min(), scale=train_data[feature].max() - train_data[feature].min())
    for feature in elemental_features
}

# Define the parameter distributions for the KNN model
knn_param_distributions = {
    'n_neighbors': randint(1, 50),
    'weights': ['uniform', 'distance'],
    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],
    'p': [1, 2, 3]
}

# Combine elemental feature distributions with KNN parameter distributions
param_distributions = {
    **elemental_distributions,
    **knn_param_distributions
}

# Initialize the KNN regressor
knn = KNeighborsRegressor()

# Perform randomized search with cross-validation
random_search = RandomizedSearchCV(
    estimator=knn,
    param_distributions=param_distributions,
    n_iter=50,  # Number of parameter settings that are sampled
    cv=5,  # Number of cross-validation folds
    scoring='neg_mean_squared_error',  # Use negative MSE to maximize
    n_jobs=-1,  # Use all available CPU cores
    random_state=42
)

# Function to calculate thermodynamic properties
def calculate_thermodynamic_properties(X):
    X_with_properties = X.copy()

    # Calculate configurational entropy
    def calculate_config_entropy(row):
        entropy = -8.314 * sum(
            (row[feature] / 100) * (0 if row[feature] == 0 else np.log(row[feature] / 100))
            for feature in elemental_features
        )
        return entropy

    X_with_properties['Config_Entropy'] = X_with_properties.apply(calculate_config_entropy, axis=1)

    # Calculate (0-T)*Entropy
    X_with_properties['(0-T)*Entropy'] = 298 * (0 - X_with_properties['Config_Entropy'])

    # Calculate Enthalpy BCC, FCC, HCP
    # Assuming you have columns for W, K, L in your dataset
    X_with_properties['Enthalpy_BCC'] = X_with_properties['W'] - X_with_properties['L']
    X_with_properties['Enthalpy_FCC'] = X_with_properties['W'] - X_with_properties['K']
    X_with_properties['Enthalpy_HCP'] = X_with_properties['V'] - X_with_properties['L']

    return X_with_properties

# Fit the randomized search to the normalized data
def fit_randomized_search(X, y):
    # Randomize and normalize elemental features
    X_randomized = X.copy()
    for feature in elemental_features:
        X_randomized[feature] = elemental_distributions[feature].rvs(size=len(X))

    # Normalize the randomized elemental features
    X_normalized = normalize_elemental_features(X_randomized)

    # Calculate thermodynamic properties based on the normalized randomized features
    X_with_properties = calculate_thermodynamic_properties(X_normalized)

    # Fit the randomized search
    random_search.fit(X_with_properties, y)

    return random_search

# Fit the model
random_search = fit_randomized_search(X, y)

# Get the best estimator
best_knn = random_search.best_estimator_

# Evaluate the best model on the normalized dataset
X_randomized = X.copy()
for feature in elemental_features:
    X_randomized[feature] = elemental_distributions[feature].rvs(size=len(X))

X_normalized = normalize_elemental_features(X_randomized)
X_with_properties = calculate_thermodynamic_properties(X_normalized)

y_pred = best_knn.predict(X_with_properties)

# Filter predictions for high yield strength (e.g., above a certain threshold)
high_yield_threshold = np.percentile(y, 75)  # Example: top 25% of yield strengths
high_yield_indices = np.where(y_pred >= high_yield_threshold)[0]

# Extract the corresponding high-entropy alloys
high_yield_alloys = df.iloc[high_yield_indices]

# Print the results
print("Best KNN Hyperparameters:", random_search.best_params_)
print("\nBest KNN Regression Performance on Normalized Data:")
print("MSE:", mean_squared_error(y, y_pred))
print("RMSE:", np.sqrt(mean_squared_error(y, y_pred)))
print("MAE:", np.mean(np.abs(y - y_pred)))
print("R²:", r2_score(y, y_pred))

print("\nHigh Yield Strength Alloys:")
print(high_yield_alloys)